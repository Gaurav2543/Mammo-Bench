{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_images():\n",
    "    dataframe = pd.read_csv('dataset.csv', low_memory=False)\n",
    "    # datasets = ['mias', 'mini-ddsm', 'inbreast', 'kau-bcmd', 'cmmd', 'cdd-cesm', 'dmid', 'rsna-screening']\n",
    "    datasets = ['cdd-cesm']\n",
    "    dataframe['new_path'] = dataframe['new_path'].replace('Original_Dataset', 'Preprocessed_Dataset')\n",
    "    dataframe.to_csv('dataset.csv', index=False)\n",
    "    for dataset in tqdm(datasets, desc='Datasets'):\n",
    "        print(f'Processing dataset: {dataset}')\n",
    "        df = dataframe[dataframe['dataset'] == dataset]\n",
    "        os.makedirs(f'Preprocessed_Dataset/{dataset}', exist_ok=True)\n",
    "        length = df.shape[0]\n",
    "\n",
    "        for i in tqdm(range(49300, length), desc='Images'):\n",
    "            output_path = f'Preprocessed_Dataset/{dataset}/{dataset}_{i}.jpg'\n",
    "            img1_path = df.iloc[i]['new_path']\n",
    "            img1_path = img1_path.replace('Original_Dataset', 'crop+clahe_Dataset')\n",
    "            img2_path = df.iloc[i]['mask_path']\n",
    "\n",
    "            img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)\n",
    "            # Check if images are loaded correctly\n",
    "            if img1 is None:\n",
    "                print(f\"Error loading image: {img1_path}\")\n",
    "                continue\n",
    "            if img2 is None:\n",
    "                print(f\"Error loading image: {img2_path}\")\n",
    "                continue\n",
    "\n",
    "            # maintain the aspect ratio of the images\n",
    "            if img1.shape[0] > img1.shape[1]:\n",
    "                img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "            else:\n",
    "                img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
    "\n",
    "            masked_image = cv2.bitwise_and(img1, img2)\n",
    "            masked_image = cv2.cvtColor(masked_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            cv2.imwrite(output_path, masked_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('Preprocessed_Dataset', exist_ok=True)\n",
    "overlap_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop the breast region after overlapping the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_breast_region(image_path, min_pixel=10):\n",
    "    if \"mias\" in image_path:\n",
    "        min_pixel = 50\n",
    "    elif \"inbreast\" in image_path:\n",
    "        min_pixel = 10\n",
    "    elif \"mini-ddsm\" in image_path:\n",
    "        min_pixel = 50\n",
    "    elif \"kau-bcmd\" in image_path:\n",
    "        min_pixel = 25\n",
    "    elif \"cmmd\" in image_path:\n",
    "        min_pixel = 10\n",
    "    elif \"cdd-cesm\" in image_path:\n",
    "        min_pixel = 10\n",
    "    elif \"rsna-screening\" in image_path:\n",
    "        min_pixel = 40\n",
    "    elif \"dmid\" in image_path:\n",
    "        min_pixel = 60\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply threshold to separate breast tissue from background\n",
    "    _, binary = cv2.threshold(img, min_pixel, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        print(f\"No contours found in image: {image_path}\")\n",
    "        return img\n",
    "    \n",
    "    # Find the largest contour (assuming it's the breast tissue)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Get bounding rectangle of the largest contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    \n",
    "    # Add some padding\n",
    "    padding = 10\n",
    "    x = max(0, x - padding)\n",
    "    y = max(0, y - padding)\n",
    "    w = min(img.shape[1] - x, w + 2*padding)\n",
    "    h = min(img.shape[0] - y, h + 2*padding)\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_img = img[y:y+h, x:x+w]\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    dataframe = pd.read_csv(\"dataset.csv\", low_memory=False)\n",
    "    df = dataframe[dataframe[\"dataset\"] == dataset]\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Preprocessing {dataset}\"):\n",
    "        img = crop_breast_region(row[\"preprocessed_image_path\"])\n",
    "        img_path = row[\"preprocessed_image_path\"].replace(\"Preprocessed_Dataset\", \"Cropped_Preprocessed_Dataset\")\n",
    "        os.makedirs(os.path.dirname(img_path), exist_ok=True)\n",
    "        cv2.imwrite(img_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['mias', 'mini-ddsm', 'inbreast', 'kau-bcmd', 'cmmd', 'cdd-cesm', 'dmid', 'rsna-screening']\n",
    "for dataset in tqdm(datasets, desc='Datasets'):\n",
    "    preprocess(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if more than 90% of the pixels are black, if they are then replace the image with the image from the crop+clahe_Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if more than 90% of the pixels are black\n",
    "black_images = []\n",
    "def check_black_images():\n",
    "    dataframe = pd.read_csv('dataset.csv', low_memory=False)\n",
    "    for i, row in tqdm(dataframe.iterrows(), total=len(dataframe), desc='Checking black images'):\n",
    "        img = cv2.imread(row['preprocessed_image_path'], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {row['preprocessed_image_path']}\")\n",
    "            continue\n",
    "        # count the total number of pixels in the image\n",
    "        total_pixels = img.shape[0] * img.shape[1]\n",
    "        # count the number of black pixels in the image\n",
    "        black_pixels = np.sum(img < 60)\n",
    "        # if more than 80% of the pixels are black\n",
    "        if black_pixels > 0.9 * total_pixels:\n",
    "            print(f\"Image with more than 90% black pixels: {row['preprocessed_image_path']}\")\n",
    "            black_images.append(row['preprocessed_image_path'])\n",
    "\n",
    "# save the black images column as a text file\n",
    "with open('black_images.txt', 'w') as f:\n",
    "    for img in black_images:\n",
    "        f.write(f\"{img}\\n\")\n",
    "\n",
    "check_black_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If more than 90% of the pixels are black, then replace the image with the image\n",
    "# from the crop+clahe_Dataset and store those images in another csv file. Define black pixel\n",
    "# as pixel value less than 60. black_images.txt contains the list of images that are mostly black\n",
    "# go to each of these images and replace them with the corresponding image from crop+clahe_Dataset\n",
    "\n",
    "def replace_black_images():\n",
    "    dataframe = pd.read_csv('dataset.csv', low_memory=False)\n",
    "    black_images = open('black_images.txt', 'r').read().split('\\n')\n",
    "    for image_path in tqdm(black_images, desc='Images'):\n",
    "        dataset = image_path.split('/')[1]\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            print(f\"Error loading image: {image_path}\")\n",
    "            continue\n",
    "        if np.mean(img) < 60:\n",
    "            new_image_path = image_path.replace('Preprocessed_Dataset', 'crop+clahe_Dataset')\n",
    "            new_img = cv2.imread(new_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if new_img is None:\n",
    "                print(f\"Error loading image: {new_image_path}\")\n",
    "                continue\n",
    "            os.makedirs(os.path.dirname(image_path), exist_ok=True)\n",
    "            cv2.imwrite(image_path, new_img)\n",
    "            dataframe.loc[dataframe['new_path'] == image_path, 'new_path'] = image_path\n",
    "\n",
    "replace_black_images()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BC-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
